{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd03f857618d8b6a3d270a8a45aea13fd0dc2a28a907e8d4ef70fe87ce2a92698f8",
   "display_name": "Python 3.7.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import AdaBoostRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据\n",
    "data_train = pd.read_csv('data/zhengqi_train.txt',sep = '\\t')\n",
    "\n",
    "data_test = pd.read_csv('data/zhengqi_test.txt',sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      V0     V1     V2     V3     V4     V6     V7     V8    V10    V12  ...  \\\n",
       "0  0.566  0.016 -0.143  0.407  0.452 -1.812 -2.360 -0.436 -0.940 -0.073  ...   \n",
       "1  0.968  0.437  0.066  0.566  0.194 -1.566 -2.360  0.332  0.188 -0.134  ...   \n",
       "2  1.013  0.568  0.235  0.370  0.112 -1.367 -2.360  0.396  0.874 -0.072  ...   \n",
       "3  0.733  0.368  0.283  0.165  0.599 -1.200 -2.086  0.403  0.011 -0.014  ...   \n",
       "4  0.684  0.638  0.260  0.209  0.337 -1.073 -2.086  0.314 -0.251  0.199  ...   \n",
       "\n",
       "     V27    V29    V30    V31    V32    V33    V34    V35    V36    V37  \n",
       "0  0.168  0.136  0.109 -0.615  0.327 -4.627 -4.789 -5.101 -2.608 -3.508  \n",
       "1  0.338 -0.128  0.124  0.032  0.600 -0.843  0.160  0.364 -0.335 -0.730  \n",
       "2  0.326 -0.009  0.361  0.277 -0.116 -0.843  0.160  0.364  0.765 -0.589  \n",
       "3  0.277  0.015  0.417  0.279  0.603 -0.843 -0.065  0.364  0.333 -0.112  \n",
       "4  0.332  0.183  1.078  0.328  0.418 -0.843 -0.215  0.364 -0.280 -0.028  \n",
       "\n",
       "[5 rows x 32 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V0</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V10</th>\n      <th>V12</th>\n      <th>...</th>\n      <th>V27</th>\n      <th>V29</th>\n      <th>V30</th>\n      <th>V31</th>\n      <th>V32</th>\n      <th>V33</th>\n      <th>V34</th>\n      <th>V35</th>\n      <th>V36</th>\n      <th>V37</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.566</td>\n      <td>0.016</td>\n      <td>-0.143</td>\n      <td>0.407</td>\n      <td>0.452</td>\n      <td>-1.812</td>\n      <td>-2.360</td>\n      <td>-0.436</td>\n      <td>-0.940</td>\n      <td>-0.073</td>\n      <td>...</td>\n      <td>0.168</td>\n      <td>0.136</td>\n      <td>0.109</td>\n      <td>-0.615</td>\n      <td>0.327</td>\n      <td>-4.627</td>\n      <td>-4.789</td>\n      <td>-5.101</td>\n      <td>-2.608</td>\n      <td>-3.508</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.968</td>\n      <td>0.437</td>\n      <td>0.066</td>\n      <td>0.566</td>\n      <td>0.194</td>\n      <td>-1.566</td>\n      <td>-2.360</td>\n      <td>0.332</td>\n      <td>0.188</td>\n      <td>-0.134</td>\n      <td>...</td>\n      <td>0.338</td>\n      <td>-0.128</td>\n      <td>0.124</td>\n      <td>0.032</td>\n      <td>0.600</td>\n      <td>-0.843</td>\n      <td>0.160</td>\n      <td>0.364</td>\n      <td>-0.335</td>\n      <td>-0.730</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.013</td>\n      <td>0.568</td>\n      <td>0.235</td>\n      <td>0.370</td>\n      <td>0.112</td>\n      <td>-1.367</td>\n      <td>-2.360</td>\n      <td>0.396</td>\n      <td>0.874</td>\n      <td>-0.072</td>\n      <td>...</td>\n      <td>0.326</td>\n      <td>-0.009</td>\n      <td>0.361</td>\n      <td>0.277</td>\n      <td>-0.116</td>\n      <td>-0.843</td>\n      <td>0.160</td>\n      <td>0.364</td>\n      <td>0.765</td>\n      <td>-0.589</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.733</td>\n      <td>0.368</td>\n      <td>0.283</td>\n      <td>0.165</td>\n      <td>0.599</td>\n      <td>-1.200</td>\n      <td>-2.086</td>\n      <td>0.403</td>\n      <td>0.011</td>\n      <td>-0.014</td>\n      <td>...</td>\n      <td>0.277</td>\n      <td>0.015</td>\n      <td>0.417</td>\n      <td>0.279</td>\n      <td>0.603</td>\n      <td>-0.843</td>\n      <td>-0.065</td>\n      <td>0.364</td>\n      <td>0.333</td>\n      <td>-0.112</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.684</td>\n      <td>0.638</td>\n      <td>0.260</td>\n      <td>0.209</td>\n      <td>0.337</td>\n      <td>-1.073</td>\n      <td>-2.086</td>\n      <td>0.314</td>\n      <td>-0.251</td>\n      <td>0.199</td>\n      <td>...</td>\n      <td>0.332</td>\n      <td>0.183</td>\n      <td>1.078</td>\n      <td>0.328</td>\n      <td>0.418</td>\n      <td>-0.843</td>\n      <td>-0.215</td>\n      <td>0.364</td>\n      <td>-0.280</td>\n      <td>-0.028</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      V0     V1     V2     V3     V4     V5     V6     V7     V8     V9  ...  \\\n",
       "0  0.368  0.380 -0.225 -0.049  0.379  0.092  0.550  0.551  0.244  0.904  ...   \n",
       "1  0.148  0.489 -0.247 -0.049  0.122 -0.201  0.487  0.493 -0.127  0.904  ...   \n",
       "2 -0.166 -0.062 -0.311  0.046 -0.055  0.063  0.485  0.493 -0.227  0.904  ...   \n",
       "3  0.102  0.294 -0.259  0.051 -0.183  0.148  0.474  0.504  0.010  0.904  ...   \n",
       "4  0.300  0.428  0.208  0.051 -0.033  0.116  0.408  0.497  0.155  0.904  ...   \n",
       "\n",
       "     V28    V29    V30    V31    V32    V33    V34    V35    V36    V37  \n",
       "0 -0.449  0.047  0.057 -0.042  0.847  0.534 -0.009 -0.190 -0.567  0.388  \n",
       "1 -0.443  0.047  0.560  0.176  0.551  0.046 -0.220  0.008 -0.294  0.104  \n",
       "2 -0.458 -0.398  0.101  0.199  0.634  0.017 -0.234  0.008  0.373  0.569  \n",
       "3 -0.456 -0.398  1.007  0.137  1.042 -0.040 -0.290  0.008 -0.666  0.391  \n",
       "4 -0.458 -0.776  0.291  0.370  0.181 -0.040 -0.290  0.008 -0.140 -0.497  \n",
       "\n",
       "[5 rows x 38 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V0</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V28</th>\n      <th>V29</th>\n      <th>V30</th>\n      <th>V31</th>\n      <th>V32</th>\n      <th>V33</th>\n      <th>V34</th>\n      <th>V35</th>\n      <th>V36</th>\n      <th>V37</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.368</td>\n      <td>0.380</td>\n      <td>-0.225</td>\n      <td>-0.049</td>\n      <td>0.379</td>\n      <td>0.092</td>\n      <td>0.550</td>\n      <td>0.551</td>\n      <td>0.244</td>\n      <td>0.904</td>\n      <td>...</td>\n      <td>-0.449</td>\n      <td>0.047</td>\n      <td>0.057</td>\n      <td>-0.042</td>\n      <td>0.847</td>\n      <td>0.534</td>\n      <td>-0.009</td>\n      <td>-0.190</td>\n      <td>-0.567</td>\n      <td>0.388</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.148</td>\n      <td>0.489</td>\n      <td>-0.247</td>\n      <td>-0.049</td>\n      <td>0.122</td>\n      <td>-0.201</td>\n      <td>0.487</td>\n      <td>0.493</td>\n      <td>-0.127</td>\n      <td>0.904</td>\n      <td>...</td>\n      <td>-0.443</td>\n      <td>0.047</td>\n      <td>0.560</td>\n      <td>0.176</td>\n      <td>0.551</td>\n      <td>0.046</td>\n      <td>-0.220</td>\n      <td>0.008</td>\n      <td>-0.294</td>\n      <td>0.104</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.166</td>\n      <td>-0.062</td>\n      <td>-0.311</td>\n      <td>0.046</td>\n      <td>-0.055</td>\n      <td>0.063</td>\n      <td>0.485</td>\n      <td>0.493</td>\n      <td>-0.227</td>\n      <td>0.904</td>\n      <td>...</td>\n      <td>-0.458</td>\n      <td>-0.398</td>\n      <td>0.101</td>\n      <td>0.199</td>\n      <td>0.634</td>\n      <td>0.017</td>\n      <td>-0.234</td>\n      <td>0.008</td>\n      <td>0.373</td>\n      <td>0.569</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.102</td>\n      <td>0.294</td>\n      <td>-0.259</td>\n      <td>0.051</td>\n      <td>-0.183</td>\n      <td>0.148</td>\n      <td>0.474</td>\n      <td>0.504</td>\n      <td>0.010</td>\n      <td>0.904</td>\n      <td>...</td>\n      <td>-0.456</td>\n      <td>-0.398</td>\n      <td>1.007</td>\n      <td>0.137</td>\n      <td>1.042</td>\n      <td>-0.040</td>\n      <td>-0.290</td>\n      <td>0.008</td>\n      <td>-0.666</td>\n      <td>0.391</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.300</td>\n      <td>0.428</td>\n      <td>0.208</td>\n      <td>0.051</td>\n      <td>-0.033</td>\n      <td>0.116</td>\n      <td>0.408</td>\n      <td>0.497</td>\n      <td>0.155</td>\n      <td>0.904</td>\n      <td>...</td>\n      <td>-0.458</td>\n      <td>-0.776</td>\n      <td>0.291</td>\n      <td>0.370</td>\n      <td>0.181</td>\n      <td>-0.040</td>\n      <td>-0.290</td>\n      <td>0.008</td>\n      <td>-0.140</td>\n      <td>-0.497</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 38 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "'ARDRegression',\n'BayesianRidge',\n'ElasticNet',\n'ElasticNetCV',\n'Hinge',\n'Huber',\n'HuberRegressor',\n'Lars',\n'LarsCV',\n'Lasso',\n'LassoCV',\n'LassoLars',\n'LassoLarsCV',\n'LassoLarsIC',\n'LinearRegression',\n'Log',\n'LogisticRegression',\n'LogisticRegressionCV',\n'ModifiedHuber',\n'MultiTaskElasticNet',\n'MultiTaskElasticNetCV',\n'MultiTaskLasso',\n'MultiTaskLassoCV',\n'OrthogonalMatchingPursuit',\n'OrthogonalMatchingPursuitCV',\n'PassiveAggressiveClassifier',\n'PassiveAggressiveRegressor',\n'Perceptron',\n'Ridge',\n'RidgeCV',\n'RidgeClassifier',\n'RidgeClassifierCV',\n'SGDClassifier',\n'SGDRegressor',\n'SquaredLoss',\n'TheilSenRegressor',\n'enet_path',\n'lars_path',\n'lars_path_gram',\n'lasso_path',\n'logistic_regression_path',\n'orthogonal_mp',\n'orthogonal_mp_gram',\n'ridge_regression',\n'RANSACRegressor',\n"
     ]
    }
   ],
   "source": [
    "for s in lm.__all__:\n",
    "    print('\\''+s+'\\''+',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ARDRegression(),\nBayesianRidge(),\nElasticNet(),\nElasticNetCV(),\nHinge(),\nHuber(),\nHuberRegressor(),\nLars(),\nLarsCV(),\nLasso(),\nLassoCV(),\nLassoLars(),\nLassoLarsCV(),\nLassoLarsIC(),\nLinearRegression(),\nLog(),\nLogisticRegression(),\nLogisticRegressionCV(),\nModifiedHuber(),\nMultiTaskElasticNet(),\nMultiTaskElasticNetCV(),\nMultiTaskLasso(),\nMultiTaskLassoCV(),\nOrthogonalMatchingPursuit(),\nOrthogonalMatchingPursuitCV(),\nPassiveAggressiveClassifier(),\nPassiveAggressiveRegressor(),\nPerceptron(),\nRidge(),\nRidgeCV(),\nRidgeClassifier(),\nRidgeClassifierCV(),\nSGDClassifier(),\nSGDRegressor(),\nSquaredLoss(),\nTheilSenRegressor(),\nenet_path(),\nlars_path(),\nlars_path_gram(),\nlasso_path(),\nlogistic_regression_path(),\northogonal_mp(),\northogonal_mp_gram(),\nridge_regression(),\nRANSACRegressor(),\n"
     ]
    }
   ],
   "source": [
    "for s in lm.__all__:\n",
    "    print(s+'(),')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_str=[\n",
    "    'ARDRegression',\n",
    "'BayesianRidge',\n",
    "'ElasticNet',\n",
    "'ElasticNetCV',\n",
    "'Hinge',\n",
    "# 'Huber',\n",
    "'HuberRegressor',\n",
    "'Lars',\n",
    "'LarsCV',\n",
    "'Lasso',\n",
    "'LassoCV',\n",
    "'LassoLars',\n",
    "'LassoLarsCV',\n",
    "'LassoLarsIC',\n",
    "'LinearRegression',\n",
    "'Log',\n",
    "'LogisticRegression',\n",
    "'LogisticRegressionCV',\n",
    "'ModifiedHuber',\n",
    "'MultiTaskElasticNet',\n",
    "'MultiTaskElasticNetCV',\n",
    "'MultiTaskLasso',\n",
    "'MultiTaskLassoCV',\n",
    "'OrthogonalMatchingPursuit',\n",
    "'OrthogonalMatchingPursuitCV',\n",
    "'PassiveAggressiveClassifier',\n",
    "'PassiveAggressiveRegressor',\n",
    "'Perceptron',\n",
    "'Ridge',\n",
    "'RidgeCV',\n",
    "'RidgeClassifier',\n",
    "'RidgeClassifierCV',\n",
    "'SGDClassifier',\n",
    "'SGDRegressor',\n",
    "'SquaredLoss',\n",
    "'TheilSenRegressor',\n",
    "'enet_path',\n",
    "'lars_path',\n",
    "'lars_path_gram',\n",
    "'lasso_path',\n",
    "'logistic_regression_path',\n",
    "'orthogonal_mp',\n",
    "'orthogonal_mp_gram',\n",
    "'ridge_regression',\n",
    "'RANSACRegressor',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[\n",
    "ARDRegression(),\n",
    "BayesianRidge(),\n",
    "ElasticNet(),\n",
    "ElasticNetCV(),\n",
    "Hinge(),\n",
    "# Huber(),\n",
    "HuberRegressor(),\n",
    "Lars(),\n",
    "LarsCV(),\n",
    "Lasso(),\n",
    "LassoCV(),\n",
    "LassoLars(),\n",
    "LassoLarsCV(),\n",
    "LassoLarsIC(),\n",
    "LinearRegression(),\n",
    "Log(),\n",
    "LogisticRegression(),\n",
    "LogisticRegressionCV(),\n",
    "ModifiedHuber(),\n",
    "MultiTaskElasticNet(),\n",
    "MultiTaskElasticNetCV(),\n",
    "MultiTaskLasso(),\n",
    "MultiTaskLassoCV(),\n",
    "OrthogonalMatchingPursuit(),\n",
    "OrthogonalMatchingPursuitCV(),\n",
    "PassiveAggressiveClassifier(),\n",
    "PassiveAggressiveRegressor(),\n",
    "Perceptron(),\n",
    "Ridge(),\n",
    "RidgeCV(),\n",
    "RidgeClassifier(),\n",
    "RidgeClassifierCV(),\n",
    "SGDClassifier(),\n",
    "SGDRegressor(),\n",
    "SquaredLoss(),\n",
    "TheilSenRegressor(),\n",
    "# enet_path(),\n",
    "# lars_path(),\n",
    "# lars_path_gram(),\n",
    "# lasso_path(),\n",
    "# logistic_regression_path(),\n",
    "# orthogonal_mp(),\n",
    "# orthogonal_mp_gram(),\n",
    "# ridge_regression(),\n",
    "# RANSACRegressor(),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ARDRegression\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "BayesianRidge\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10674100366338017\n",
      " test均方误差 =  0.12445412956292763\n",
      " 整体均方误差 =  0.1120586214455504\n",
      " train均方误差 =  0.13050166329496052\n",
      " test均方误差 =  0.1317521043548339\n",
      " 整体均方误差 =  0.13087705539984634\n",
      "ElasticNet\n",
      "----------begin----------------\n",
      " train均方误差 =  0.22763863762185327\n",
      " test均方误差 =  0.24249605224582152\n",
      " 整体均方误差 =  0.23209894872953346\n",
      " train均方误差 =  0.27027103742689257\n",
      " test均方误差 =  0.2765965211546695\n",
      " 整体均方误差 =  0.2721699967038949\n",
      "ElasticNetCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10771392049915864\n",
      " test均方误差 =  0.12646353762232962\n",
      " 整体均方误差 =  0.11334270098592776\n",
      " train均方误差 =  0.12733650166938631\n",
      " test均方误差 =  0.13090577374653684\n",
      " 整体均方误差 =  0.12840802483105168\n",
      "Hinge\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "HuberRegressor\n",
      "----------begin----------------\n",
      "C:\\Users\\cascara\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\cascara\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\cascara\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\cascara\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\cascara\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\cascara\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      " train均方误差 =  0.10971107604481133\n",
      " test均方误差 =  0.130198463479225\n",
      " 整体均方误差 =  0.11586154865756643\n",
      "C:\\Users\\cascara\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\cascara\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\cascara\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\cascara\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      " train均方误差 =  0.11667438461301115\n",
      " test均方误差 =  0.12173943987479063\n",
      " 整体均方误差 =  0.11819495348834452\n",
      "Lars\n",
      "----------begin----------------\n",
      " train均方误差 =  0.1350648225168062\n",
      " test均方误差 =  0.1550573899868352\n",
      " 整体均方误差 =  0.1410667463383142\n",
      " train均方误差 =  0.15327792057991757\n",
      " test均方误差 =  0.15225531727500688\n",
      " 整体均方误差 =  0.1529709271362342\n",
      "LarsCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.1369153905027045\n",
      " test均方误差 =  0.15346326276240305\n",
      " 整体均方误差 =  0.1418831901042137\n",
      " train均方误差 =  0.1884773008629916\n",
      " test均方误差 =  0.1974026700957175\n",
      " 整体均方误差 =  0.19115676593389652\n",
      "Lasso\n",
      "----------begin----------------\n",
      " train均方误差 =  0.46117942760210406\n",
      " test均方误差 =  0.46083121582286096\n",
      " 整体均方误差 =  0.4610748917251637\n",
      " train均方误差 =  0.3798888635741739\n",
      " test均方误差 =  0.38874292389909737\n",
      " 整体均方误差 =  0.38254692115786804\n",
      "LassoCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10638711633286439\n",
      " test均方误差 =  0.1230550752841858\n",
      " 整体均方误差 =  0.11139096689061913\n",
      " train均方误差 =  0.12556398932645785\n",
      " test均方误差 =  0.1301246490011221\n",
      " 整体均方误差 =  0.12693313473432968\n",
      "LassoLars\n",
      "----------begin----------------\n",
      " train均方误差 =  0.9912173400232737\n",
      " test均方误差 =  0.9326660453860068\n",
      " 整体均方误差 =  0.9736397872357008\n",
      " train均方误差 =  1.0009730326055086\n",
      " test均方误差 =  0.9484690969625428\n",
      " 整体均方误差 =  0.9852109438927485\n",
      "LassoLarsCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10637633567358222\n",
      " test均方误差 =  0.12354977069031062\n",
      " 整体均方误差 =  0.1115319340667621\n",
      " train均方误差 =  0.11292964017319923\n",
      " test均方误差 =  0.12029900520189676\n",
      " 整体均方误差 =  0.11514198071332415\n",
      "LassoLarsIC\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10931123046434098\n",
      " test均方误差 =  0.1282276547312031\n",
      " 整体均方误差 =  0.1149900877494412\n",
      " train均方误差 =  0.12735455406803703\n",
      " test均方误差 =  0.1335662649988045\n",
      " 整体均方误差 =  0.1292193578689288\n",
      "LinearRegression\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10948295194122916\n",
      " test均方误差 =  0.12886665815327414\n",
      " 整体均方误差 =  0.11530209089062077\n",
      " train均方误差 =  0.12318094515625043\n",
      " test均方误差 =  0.12818849235721747\n",
      " 整体均方误差 =  0.124684249665682\n",
      "Log\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "LogisticRegression\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "LogisticRegressionCV\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "ModifiedHuber\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "MultiTaskElasticNet\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "MultiTaskElasticNetCV\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "MultiTaskLasso\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "MultiTaskLassoCV\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "OrthogonalMatchingPursuit\n",
      "----------begin----------------\n",
      " train均方误差 =  0.13143600141058398\n",
      " test均方误差 =  0.1532789159844323\n",
      " 整体均方误差 =  0.13799341378438124\n",
      " train均方误差 =  0.15547091343733246\n",
      " test均方误差 =  0.16800073426408269\n",
      " 整体均方误差 =  0.15923246283372874\n",
      "OrthogonalMatchingPursuitCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.12380045699096948\n",
      " test均方误差 =  0.14681157421778604\n",
      " 整体均方误差 =  0.1307085728620394\n",
      " train均方误差 =  0.15052864845601904\n",
      " test均方误差 =  0.1621390988640973\n",
      " 整体均方误差 =  0.1540141957218791\n",
      "PassiveAggressiveClassifier\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "PassiveAggressiveRegressor\n",
      "----------begin----------------\n",
      " train均方误差 =  0.13552780681737758\n",
      " test均方误差 =  0.16024375969895505\n",
      " 整体均方误差 =  0.1429477275751088\n",
      " train均方误差 =  0.16767830064646078\n",
      " test均方误差 =  0.16833624216600623\n",
      " 整体均方误差 =  0.16787581979377583\n",
      "Perceptron\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "Ridge\n",
      "----------begin----------------\n",
      " train均方误差 =  0.11157755371541932\n",
      " test均方误差 =  0.13076705278664955\n",
      " 整体均方误差 =  0.11733839017482257\n",
      " train均方误差 =  0.12917580160839512\n",
      " test均方误差 =  0.13314712376663915\n",
      " 整体均方误差 =  0.13036802332279873\n",
      "RidgeCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10808597932436956\n",
      " test均方误差 =  0.12737752407004144\n",
      " 整体均方误差 =  0.1138774506867302\n",
      " train均方误差 =  0.12810328421432315\n",
      " test均方误差 =  0.1327733334967146\n",
      " 整体均方误差 =  0.12950526923088598\n",
      "RidgeClassifier\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "RidgeClassifierCV\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "SGDClassifier\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "SGDRegressor\n",
      "----------begin----------------\n",
      " train均方误差 =  0.11591063794146944\n",
      " test均方误差 =  0.13403386375664786\n",
      " 整体均方误差 =  0.12135137089914247\n",
      " train均方误差 =  0.12900320859842943\n",
      " test均方误差 =  0.13223300608553856\n",
      " 整体均方误差 =  0.12997281885512044\n",
      "SquaredLoss\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "TheilSenRegressor\n",
      "----------begin----------------\n",
      " train均方误差 =  0.110591084247665\n",
      " test均方误差 =  0.131448623643534\n",
      " 整体均方误差 =  0.1168526793502337\n",
      " train均方误差 =  0.1281040189056994\n",
      " test均方误差 =  0.1310453031907724\n",
      " 整体均方误差 =  0.1289870152613636\n"
     ]
    }
   ],
   "source": [
    "df_train=pd.DataFrame.copy(data_train)\n",
    "y = df_train.target\n",
    "X = df_train.drop([\"target\"],axis=1)\n",
    "# X_train,X_valid,y_train,y_valid=train_test_split(X,y,test_size=0.3,random_state=100)\n",
    "train_x, test_x, train_y, test_y=train_test_split(X,y,test_size=0.3,random_state=100)\n",
    "i=0\n",
    "for model in models:\n",
    "    model_name=models_str[i]\n",
    "    i+=1\n",
    "    print(model_name)\n",
    "    print('----------begin----------------')\n",
    "\n",
    "    try:\n",
    "        regressor=AdaBoostRegressor(base_estimator=model)#ElasticNet())#LinearRegression())\n",
    "        regressor.fit(train_x,train_y)\n",
    "        pred_y = regressor.predict(train_x)\n",
    "        mse = mean_squared_error(train_y, pred_y)\n",
    "        print(\" train均方误差 = \",mse)\n",
    "\n",
    "        pred_y = regressor.predict(test_x)\n",
    "        mse = mean_squared_error(test_y, pred_y)\n",
    "        print(\" test均方误差 = \",mse)\n",
    "\n",
    "        pred_y = regressor.predict(X)\n",
    "        mse = mean_squared_error(y, pred_y)\n",
    "        print(\" 整体均方误差 = \",mse)\n",
    "\n",
    "        # 整体训练\n",
    "        regressor.fit(X,y)\n",
    "        pred_y = regressor.predict(train_x)\n",
    "        mse = mean_squared_error(train_y, pred_y)\n",
    "        print(\" train均方误差 = \",mse)\n",
    "\n",
    "        pred_y = regressor.predict(test_x)\n",
    "        mse = mean_squared_error(test_y, pred_y)\n",
    "        print(\" test均方误差 = \",mse)\n",
    "\n",
    "        pred_y = regressor.predict(X)\n",
    "        mse = mean_squared_error(y, pred_y)\n",
    "        print(\" 整体均方误差 = \",mse)\n",
    "\n",
    "        # 保cun\n",
    "\n",
    "\n",
    "        pred_y = regressor.predict(data_test)\n",
    "        pd_pred=pd.Series(pred_y)\n",
    "        pd_pred.to_csv(model_name+'pred_ada_whole.txt',header=None,index=False)\n",
    "\n",
    "    except:\n",
    "        print('----------failed----------------')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ARDRegression\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "BayesianRidge\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10367868763699382\n",
      " test均方误差 =  0.12105111183199115\n",
      " 整体均方误差 =  0.10889402412489642\n",
      " train均方误差 =  0.10426259798160194\n",
      " test均方误差 =  0.1149690610311445\n",
      " 整体均方误差 =  0.1074767612308933\n",
      "ElasticNet\n",
      "----------begin----------------\n",
      " train均方误差 =  0.560757700357684\n",
      " test均方误差 =  0.536729130449065\n",
      " 整体均方误差 =  0.5535441372999372\n",
      " train均方误差 =  0.5787156324824309\n",
      " test均方误差 =  0.551468991256042\n",
      " 整体均方误差 =  0.5705359794549796\n",
      "ElasticNetCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10405233217855427\n",
      " test均方误差 =  0.12238477016649377\n",
      " 整体均方误差 =  0.10955587225318847\n",
      " train均方误差 =  0.10441603701339162\n",
      " test均方误差 =  0.1165144049188842\n",
      " 整体均方误差 =  0.10804806089637711\n",
      "Hinge\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "HuberRegressor\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10460972108381726\n",
      " test均方误差 =  0.12113410511037129\n",
      " 整体均方误差 =  0.10957046933555628\n",
      "C:\\Users\\cascara\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      " train均方误差 =  0.10523470700190767\n",
      " test均方误差 =  0.11594532490010037\n",
      " 整体均方误差 =  0.10845011756898976\n",
      "Lars\n",
      "----------begin----------------\n",
      " train均方误差 =  1.782157007735299\n",
      " test均方误差 =  1.995980619120597\n",
      " 整体均方误差 =  1.8463485143388494\n",
      " train均方误差 =  1.5657852425384247\n",
      " test均方误差 =  1.5924984156172564\n",
      " 整体均方误差 =  1.5738047442902763\n",
      "LarsCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.1780223802585404\n",
      " test均方误差 =  0.19017916921965664\n",
      " 整体均方误差 =  0.18167194259555142\n",
      " train均方误差 =  0.2466727486890972\n",
      " test均方误差 =  0.2520758242955859\n",
      " 整体均方误差 =  0.2482947938936767\n",
      "Lasso\n",
      "----------begin----------------\n",
      " train均方误差 =  0.9876453112085596\n",
      " test均方误差 =  0.9226027495930467\n",
      " 整体均方误差 =  0.9681190297263401\n",
      " train均方误差 =  0.9879110945856205\n",
      " test均方误差 =  0.9210978700105859\n",
      " 整体均方误差 =  0.9678532463492788\n",
      "LassoCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10372463280202274\n",
      " test均方误差 =  0.12167644176850953\n",
      " 整体均方误差 =  0.10911390509216956\n",
      " train均方误差 =  0.10425177531292189\n",
      " test均方误差 =  0.11614551242858358\n",
      " 整体均方误差 =  0.10782236744563613\n",
      "LassoLars\n",
      "----------begin----------------\n",
      " train均方误差 =  0.9876453112085596\n",
      " test均方误差 =  0.9226027495930467\n",
      " 整体均方误差 =  0.9681190297263401\n",
      " train均方误差 =  0.9879110945856205\n",
      " test均方误差 =  0.9210978700105859\n",
      " 整体均方误差 =  0.9678532463492788\n",
      "LassoLarsCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10375917564357164\n",
      " test均方误差 =  0.12161630062076462\n",
      " 整体均方误差 =  0.10912002306574142\n",
      " train均方误差 =  0.10450494518546177\n",
      " test均方误差 =  0.11705438165947318\n",
      " 整体均方误差 =  0.10827238335130937\n",
      "LassoLarsIC\n",
      "----------begin----------------\n",
      " train均方误差 =  0.1143446817665273\n",
      " test均方误差 =  0.13522083184690692\n",
      " 整体均方误差 =  0.12061186394093489\n",
      " train均方误差 =  0.10441143333212859\n",
      " test均方误差 =  0.11671116952130878\n",
      " 整体均方误差 =  0.10810390953573634\n",
      "LinearRegression\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10333045503103827\n",
      " test均方误差 =  0.11990149947528927\n",
      " 整体均方误差 =  0.108305211102079\n",
      " train均方误差 =  0.10428532702544804\n",
      " test均方误差 =  0.11441348705930733\n",
      " 整体均方误差 =  0.10732587922397853\n",
      "Log\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "LogisticRegression\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "LogisticRegressionCV\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "ModifiedHuber\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "MultiTaskElasticNet\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "MultiTaskElasticNetCV\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "MultiTaskLasso\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "MultiTaskLassoCV\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "OrthogonalMatchingPursuit\n",
      "----------begin----------------\n",
      " train均方误差 =  0.15949143327042392\n",
      " test均方误差 =  0.1742488341479426\n",
      " 整体均方误差 =  0.16392171947569012\n",
      " train均方误差 =  0.14835649835966375\n",
      " test均方误差 =  0.1619856383729972\n",
      " 整体均方误差 =  0.1524480719024477\n",
      "OrthogonalMatchingPursuitCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.1391746264817531\n",
      " test均方误差 =  0.15915654066915513\n",
      " 整体均方误差 =  0.14517335210518714\n",
      " train均方误差 =  0.13748302675170718\n",
      " test均方误差 =  0.15447872354934405\n",
      " 整体均方误差 =  0.1425852667529368\n",
      "PassiveAggressiveClassifier\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "PassiveAggressiveRegressor\n",
      "----------begin----------------\n",
      " train均方误差 =  0.25127276124351655\n",
      " test均方误差 =  0.2651068555585156\n",
      " 整体均方误差 =  0.2554258636573338\n",
      " train均方误差 =  0.18655376958449554\n",
      " test均方误差 =  0.18577683990317387\n",
      " 整体均方误差 =  0.18632052926811538\n",
      "Perceptron\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "Ridge\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10337065374942132\n",
      " test均方误差 =  0.12020292118503374\n",
      " 整体均方误差 =  0.10842383098857504\n",
      " train均方误差 =  0.10424162798046392\n",
      " test均方误差 =  0.11459096002225247\n",
      " 整体均方误差 =  0.10734857773123631\n",
      "RidgeCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.1033309100337049\n",
      " test均方误差 =  0.11992923711410754\n",
      " 整体均方误差 =  0.10831385656372881\n",
      " train均方误差 =  0.10427869350299528\n",
      " test均方误差 =  0.11442977424853665\n",
      " 整体均方误差 =  0.10732612667695109\n",
      "RidgeClassifier\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "RidgeClassifierCV\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "SGDClassifier\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "SGDRegressor\n",
      "----------begin----------------\n",
      " train均方误差 =  0.11241711824621999\n",
      " test均方误差 =  0.13240616632162255\n",
      " 整体均方误差 =  0.11841798551816392\n",
      " train均方误差 =  0.11077456393863384\n",
      " test均方误差 =  0.12633722112519577\n",
      " 整体均方误差 =  0.1154465943336301\n",
      "SquaredLoss\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "TheilSenRegressor\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10808805230007375\n",
      " test均方误差 =  0.12131947611816099\n",
      " 整体均方误差 =  0.11206022835626545\n",
      " train均方误差 =  0.1086050903367162\n",
      " test均方误差 =  0.11700175483427992\n",
      " 整体均方误差 =  0.11112583414536845\n"
     ]
    }
   ],
   "source": [
    "df_train=pd.DataFrame.copy(data_train)\n",
    "y = df_train.target\n",
    "X = df_train.drop([\"target\"],axis=1)\n",
    "# X_train,X_valid,y_train,y_valid=train_test_split(X,y,test_size=0.3,random_state=100)\n",
    "train_x, test_x, train_y, test_y=train_test_split(X,y,test_size=0.3,random_state=100)\n",
    "i=0\n",
    "for model in models:\n",
    "    model_name=models_str[i]\n",
    "    i+=1\n",
    "    print(model_name)\n",
    "    print('----------begin----------------')\n",
    "\n",
    "    try:\n",
    "        # regressor=AdaBoostRegressor(base_estimator=model)#ElasticNet())\n",
    "        regressor=model\n",
    "        #LinearRegression())\n",
    "        regressor.fit(train_x,train_y)\n",
    "        pred_y = regressor.predict(train_x)\n",
    "        mse = mean_squared_error(train_y, pred_y)\n",
    "        print(\" train均方误差 = \",mse)\n",
    "\n",
    "        pred_y = regressor.predict(test_x)\n",
    "        mse = mean_squared_error(test_y, pred_y)\n",
    "        print(\" test均方误差 = \",mse)\n",
    "\n",
    "        pred_y = regressor.predict(X)\n",
    "        mse = mean_squared_error(y, pred_y)\n",
    "        print(\" 整体均方误差 = \",mse)\n",
    "\n",
    "        # 整体训练\n",
    "        regressor.fit(X,y)\n",
    "        pred_y = regressor.predict(train_x)\n",
    "        mse = mean_squared_error(train_y, pred_y)\n",
    "        print(\" train均方误差 = \",mse)\n",
    "\n",
    "        pred_y = regressor.predict(test_x)\n",
    "        mse = mean_squared_error(test_y, pred_y)\n",
    "        print(\" test均方误差 = \",mse)\n",
    "\n",
    "        pred_y = regressor.predict(X)\n",
    "        mse = mean_squared_error(y, pred_y)\n",
    "        print(\" 整体均方误差 = \",mse)\n",
    "\n",
    "        # 保cun\n",
    "\n",
    "\n",
    "        pred_y = regressor.predict(data_test)\n",
    "        pd_pred=pd.Series(pred_y)\n",
    "        pd_pred.to_csv(model_name+'pred_ada_whole.txt',header=None,index=False)\n",
    "\n",
    "    except:\n",
    "        print('----------failed----------------')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " train均方误差 =  0.23032283451079696\n test均方误差 =  0.24579945486819238\n 整体均方误差 =  0.23496903598235577\n"
     ]
    }
   ],
   "source": [
    "df_train=pd.DataFrame.copy(data_train)\n",
    "y = df_train.target\n",
    "X = df_train.drop([\"target\"],axis=1)\n",
    "# X_train,X_valid,y_train,y_valid=train_test_split(X,y,test_size=0.3,random_state=100)\n",
    "train_x, test_x, train_y, test_y=train_test_split(X,y,test_size=0.3,random_state=100)\n",
    "regressor=AdaBoostRegressor(base_estimator=ElasticNet())#LinearRegression())\n",
    "regressor.fit(train_x,train_y)\n",
    "pred_y = regressor.predict(train_x)\n",
    "mse = mean_squared_error(train_y, pred_y)\n",
    "print(\" train均方误差 = \",mse)\n",
    "\n",
    "pred_y = regressor.predict(test_x)\n",
    "mse = mean_squared_error(test_y, pred_y)\n",
    "print(\" test均方误差 = \",mse)\n",
    "\n",
    "pred_y = regressor.predict(X)\n",
    "mse = mean_squared_error(y, pred_y)\n",
    "print(\" 整体均方误差 = \",mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " train均方误差 =  0.12567036415362687\n test均方误差 =  0.12852850862553677\n 整体均方误差 =  0.1265284012925278\n"
     ]
    }
   ],
   "source": [
    "# 整体训练\n",
    "regressor.fit(X,y)\n",
    "pred_y = regressor.predict(train_x)\n",
    "mse = mean_squared_error(train_y, pred_y)\n",
    "print(\" train均方误差 = \",mse)\n",
    "\n",
    "pred_y = regressor.predict(test_x)\n",
    "mse = mean_squared_error(test_y, pred_y)\n",
    "print(\" test均方误差 = \",mse)\n",
    "\n",
    "pred_y = regressor.predict(X)\n",
    "mse = mean_squared_error(y, pred_y)\n",
    "print(\" 整体均方误差 = \",mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = regressor.predict(data_test)\n",
    "pd_pred=pd.Series(pred_y)\n",
    "pd_pred.to_csv('pred_ada_reg_whole.txt',header=None,index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " train均方误差 =  0.10951965511089094\n test均方误差 =  0.12814157087505196\n 整体均方误差 =  0.11511009865920382\n"
     ]
    }
   ],
   "source": [
    "df_train=pd.DataFrame.copy(data_train)\n",
    "df_train.drop([\"V5\",\"V9\",\"V11\",\"V17\",\"V22\",\"V28\"],axis=1,inplace=True)\n",
    "y = df_train.target\n",
    "X = df_train.drop([\"target\"],axis=1)\n",
    "X_train,X_valid,y_train,y_valid=train_test_split(X,y,test_size=0.3,random_state=100)\n",
    "train_x, test_x, train_y, test_y=train_test_split(X,y,test_size=0.3,random_state=100)\n",
    "regressor=AdaBoostRegressor(base_estimator=LinearRegression())\n",
    "regressor.fit(train_x,train_y)\n",
    "pred_y = regressor.predict(train_x)\n",
    "mse = mean_squared_error(train_y, pred_y)\n",
    "print(\" train均方误差 = \",mse)\n",
    "\n",
    "pred_y = regressor.predict(test_x)\n",
    "mse = mean_squared_error(test_y, pred_y)\n",
    "print(\" test均方误差 = \",mse)\n",
    "\n",
    "pred_y = regressor.predict(X)\n",
    "mse = mean_squared_error(y, pred_y)\n",
    "print(\" 整体均方误差 = \",mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " train均方误差 =  0.12880211583779969\n test均方误差 =  0.13737635072201332\n 整体均方误差 =  0.13137616765380147\n"
     ]
    }
   ],
   "source": [
    "regressor.fit(X,y)\n",
    "pred_y = regressor.predict(train_x)\n",
    "mse = mean_squared_error(train_y, pred_y)\n",
    "print(\" train均方误差 = \",mse)\n",
    "\n",
    "pred_y = regressor.predict(test_x)\n",
    "mse = mean_squared_error(test_y, pred_y)\n",
    "print(\" test均方误差 = \",mse)\n",
    "\n",
    "pred_y = regressor.predict(X)\n",
    "mse = mean_squared_error(y, pred_y)\n",
    "print(\" 整体均方误差 = \",mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.DataFrame.copy(data_test)\n",
    "df_test.drop([\"V5\",\"V9\",\"V11\",\"V17\",\"V22\",\"V28\"],axis=1,inplace=True)\n",
    "pred_y = regressor.predict(df_test)\n",
    "pd_pred=pd.Series(pred_y)\n",
    "pd_pred.to_csv('pred_ada_reg_part.txt',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ARDRegression\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "BayesianRidge\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10667530995664214\n",
      " test均方误差 =  0.1255235982166656\n",
      " 整体均方误差 =  0.11233371228401066\n",
      " train均方误差 =  0.1072526511117043\n",
      " test均方误差 =  0.11987762332444894\n",
      " 整体均方误差 =  0.11104276569219237\n",
      "ElasticNet\n",
      "----------begin----------------\n",
      " train均方误差 =  0.560757700357684\n",
      " test均方误差 =  0.536729130449065\n",
      " 整体均方误差 =  0.5535441372999372\n",
      " train均方误差 =  0.5787156324824309\n",
      " test均方误差 =  0.551468991256042\n",
      " 整体均方误差 =  0.5705359794549796\n",
      "ElasticNetCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.1070285329882432\n",
      " test均方误差 =  0.12650818539909975\n",
      " 整体均方误差 =  0.1128764757306991\n",
      " train均方误差 =  0.10750351456987985\n",
      " test均方误差 =  0.12098823564676099\n",
      " 整体均方误差 =  0.11155173242779397\n",
      "Hinge\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "HuberRegressor\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10740913688612502\n",
      " test均方误差 =  0.12501327250729505\n",
      " 整体均方误差 =  0.1126940349413724\n",
      " train均方误差 =  0.1082192456081243\n",
      " test均方误差 =  0.12051730776302139\n",
      " 整体均方误差 =  0.11191121925365609\n",
      "Lars\n",
      "----------begin----------------\n",
      " train均方误差 =  1.4849067473993163\n",
      " test均方误差 =  1.5765964221888553\n",
      " 整体均方误差 =  1.512432698937589\n",
      " train均方误差 =  1.551730256091892\n",
      " test均方误差 =  1.5655113292785314\n",
      " 整体均方误差 =  1.5558674411517317\n",
      "LarsCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.1780223802585404\n",
      " test均方误差 =  0.1901791692196566\n",
      " 整体均方误差 =  0.18167194259555142\n",
      " train均方误差 =  0.23962508187407108\n",
      " test均方误差 =  0.24563597815895782\n",
      " 整体均方误差 =  0.24142959956070437\n",
      "Lasso\n",
      "----------begin----------------\n",
      " train均方误差 =  0.9876453112085596\n",
      " test均方误差 =  0.9226027495930467\n",
      " 整体均方误差 =  0.9681190297263401\n",
      " train均方误差 =  0.9879110945856205\n",
      " test均方误差 =  0.9210978700105859\n",
      " 整体均方误差 =  0.9678532463492788\n",
      "LassoCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10673689980590749\n",
      " test均方误差 =  0.12585551500072534\n",
      " 整体均方误差 =  0.11247645637581993\n",
      " train均方误差 =  0.10753024335238018\n",
      " test均方误差 =  0.12118829154099753\n",
      " 整体均方误差 =  0.1116304953536029\n",
      "LassoLars\n",
      "----------begin----------------\n",
      " train均方误差 =  0.9876453112085596\n",
      " test均方误差 =  0.9226027495930467\n",
      " 整体均方误差 =  0.9681190297263401\n",
      " train均方误差 =  0.9879110945856205\n",
      " test均方误差 =  0.9210978700105859\n",
      " 整体均方误差 =  0.9678532463492788\n",
      "LassoLarsCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10673648497222432\n",
      " test均方误差 =  0.12578255067573946\n",
      " 整体均方误差 =  0.11245426162213693\n",
      " train均方误差 =  0.10834707413283108\n",
      " test均方误差 =  0.12326825457478807\n",
      " 整体均方误差 =  0.11282652823365405\n",
      "LassoLarsIC\n",
      "----------begin----------------\n",
      " train均方误差 =  0.11646262342243413\n",
      " test均方误差 =  0.13619366779501466\n",
      " 整体均方误差 =  0.1223860359816541\n",
      " train均方误差 =  0.10829916205479988\n",
      " test均方误差 =  0.12315947467289594\n",
      " 整体均方误差 =  0.11276034316279479\n",
      "LinearRegression\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10640440227394696\n",
      " test均方误差 =  0.1244925908231392\n",
      " 整体均方误差 =  0.11183461677261375\n",
      " train均方误差 =  0.10729355187040013\n",
      " test均方误差 =  0.11937959510837122\n",
      " 整体均方误差 =  0.11092187579260267\n",
      "Log\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "LogisticRegression\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "LogisticRegressionCV\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "ModifiedHuber\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "MultiTaskElasticNet\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "MultiTaskElasticNetCV\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "MultiTaskLasso\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "MultiTaskLassoCV\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "OrthogonalMatchingPursuit\n",
      "----------begin----------------\n",
      " train均方误差 =  0.15949143327042392\n",
      " test均方误差 =  0.1742488341479426\n",
      " 整体均方误差 =  0.16392171947569012\n",
      " train均方误差 =  0.14835649835966375\n",
      " test均方误差 =  0.1619856383729972\n",
      " 整体均方误差 =  0.1524480719024477\n",
      "OrthogonalMatchingPursuitCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.13925297458779423\n",
      " test均方误差 =  0.1567802562903427\n",
      " 整体均方误差 =  0.14451480050057453\n",
      " train均方误差 =  0.14164016526902615\n",
      " test均方误差 =  0.14984618330339122\n",
      " 整体均方误差 =  0.14410367553072784\n",
      "PassiveAggressiveClassifier\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "PassiveAggressiveRegressor\n",
      "----------begin----------------\n",
      " train均方误差 =  0.17968267175369293\n",
      " test均方误差 =  0.2044751092512886\n",
      " 整体均方误差 =  0.18712555378638526\n",
      " train均方误差 =  0.13948459017997095\n",
      " test均方误差 =  0.15461995246132393\n",
      " 整体均方误差 =  0.14402834333022477\n",
      "Perceptron\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "Ridge\n",
      "----------begin----------------\n",
      " train均方误差 =  0.1064397679358769\n",
      " test均方误差 =  0.12479727088125844\n",
      " 整体均方误差 =  0.11195083270514485\n",
      " train均方误差 =  0.10724774403649959\n",
      " test均方误差 =  0.11955489647930014\n",
      " 整体均方误差 =  0.11094244665696637\n",
      "RidgeCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10640480173792448\n",
      " test均方误差 =  0.12452133918041673\n",
      " 整体均方误差 =  0.11184352679424055\n",
      " train均方误差 =  0.10728686953005763\n",
      " test均方误差 =  0.11939591825550937\n",
      " 整体均方误差 =  0.11092209987803776\n",
      "RidgeClassifier\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "RidgeClassifierCV\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "SGDClassifier\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "SGDRegressor\n",
      "----------begin----------------\n",
      " train均方误差 =  0.11455559361622128\n",
      " test均方误差 =  0.1392194055238071\n",
      " 整体均方误差 =  0.12195986124914264\n",
      " train均方误差 =  0.11404434247063802\n",
      " test均方误差 =  0.12923827705433139\n",
      " 整体均方误差 =  0.11860567948035484\n",
      "SquaredLoss\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "TheilSenRegressor\n",
      "----------begin----------------\n",
      " train均方误差 =  0.11087749164154549\n",
      " test均方误差 =  0.12814554234372794\n",
      " 整体均方误差 =  0.11606149439735998\n",
      " train均方误差 =  0.1117642467555902\n",
      " test均方误差 =  0.1213072019088646\n",
      " 整体均方误差 =  0.11462911590998387\n"
     ]
    }
   ],
   "source": [
    "df_train=pd.DataFrame.copy(data_train)\n",
    "df_train.drop([\"V5\",\"V9\",\"V11\",\"V17\",\"V22\",\"V28\"],axis=1,inplace=True)\n",
    "\n",
    "y = df_train.target\n",
    "X = df_train.drop([\"target\"],axis=1)\n",
    "train_x, test_x, train_y, test_y=train_test_split(X,y,test_size=0.3,random_state=100)\n",
    "\n",
    "df_test=pd.DataFrame.copy(data_test)\n",
    "df_test.drop([\"V5\",\"V9\",\"V11\",\"V17\",\"V22\",\"V28\"],axis=1,inplace=True)\n",
    "\n",
    "i=0\n",
    "for model in models:\n",
    "    model_name=models_str[i]\n",
    "    i+=1\n",
    "    print(model_name)\n",
    "    print('----------begin----------------')\n",
    "\n",
    "    try:\n",
    "        # regressor=AdaBoostRegressor(base_estimator=model)#ElasticNet())\n",
    "        regressor=model\n",
    "        #LinearRegression())\n",
    "        regressor.fit(train_x,train_y)\n",
    "        pred_y = regressor.predict(train_x)\n",
    "        mse = mean_squared_error(train_y, pred_y)\n",
    "        print(\" train均方误差 = \",mse)\n",
    "\n",
    "        pred_y = regressor.predict(test_x)\n",
    "        mse = mean_squared_error(test_y, pred_y)\n",
    "        print(\" test均方误差 = \",mse)\n",
    "\n",
    "        pred_y = regressor.predict(X)\n",
    "        mse = mean_squared_error(y, pred_y)\n",
    "        print(\" 整体均方误差 = \",mse)\n",
    "\n",
    "        # 整体训练\n",
    "        regressor.fit(X,y)\n",
    "        pred_y = regressor.predict(train_x)\n",
    "        mse = mean_squared_error(train_y, pred_y)\n",
    "        print(\" train均方误差 = \",mse)\n",
    "\n",
    "        pred_y = regressor.predict(test_x)\n",
    "        mse = mean_squared_error(test_y, pred_y)\n",
    "        print(\" test均方误差 = \",mse)\n",
    "\n",
    "        pred_y = regressor.predict(X)\n",
    "        mse = mean_squared_error(y, pred_y)\n",
    "        print(\" 整体均方误差 = \",mse)\n",
    "\n",
    "        # 保cun\n",
    "\n",
    "\n",
    "        pred_y = regressor.predict(df_test)\n",
    "        pd_pred=pd.Series(pred_y)\n",
    "        pd_pred.to_csv('drop/'+model_name+'pred_ada_whole.txt',header=None,index=False)\n",
    "\n",
    "    except:\n",
    "        print('----------failed----------------')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ARDRegression\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10399884985058364\n",
      " test均方误差 =  0.1205686266038351\n",
      " 整体均方误差 =  0.10897322535095379\n",
      " train均方误差 =  0.10485649663566969\n",
      " test均方误差 =  0.11590517087017374\n",
      " 整体均方误差 =  0.10817339433695605\n",
      "BayesianRidge\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10375681512876293\n",
      " test均方误差 =  0.12178552202656612\n",
      " 整体均方误差 =  0.10916917277432919\n",
      " train均方误差 =  0.10429482151784669\n",
      " test均方误差 =  0.11624043477381762\n",
      " 整体均方误差 =  0.10788098727024517\n",
      "ElasticNet\n",
      "----------begin----------------\n",
      " train均方误差 =  0.560757700357684\n",
      " test均方误差 =  0.536729130449065\n",
      " 整体均方误差 =  0.5535441372999372\n",
      " train均方误差 =  0.5787156324824309\n",
      " test均方误差 =  0.551468991256042\n",
      " 整体均方误差 =  0.5705359794549796\n",
      "ElasticNetCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.1041342764927431\n",
      " test均方误差 =  0.12270997612705259\n",
      " 整体均方误差 =  0.10971084560041149\n",
      " train均方误差 =  0.10455781870991224\n",
      " test均方误差 =  0.11741932123842072\n",
      " 整体均方误差 =  0.10841894152577679\n",
      "Hinge\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "HuberRegressor\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10477446557612108\n",
      " test均方误差 =  0.12197645122017087\n",
      " 整体均方误差 =  0.10993863508906815\n",
      "C:\\Users\\cascara\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      " train均方误差 =  0.10536363534972024\n",
      " test均方误差 =  0.1171985578641516\n",
      " 整体均方误差 =  0.10891657088296537\n",
      "Lars\n",
      "----------begin----------------\n",
      " train均方误差 =  5.525876743490628\n",
      " test均方误差 =  6.597783874846983\n",
      " 整体均方误差 =  5.847671578284936\n",
      " train均方误差 =  1.5654707700183021\n",
      " test均方误差 =  1.5931598040585588\n",
      " 整体均方误差 =  1.5737832327997783\n",
      "LarsCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.1780223802585403\n",
      " test均方误差 =  0.19017916921965655\n",
      " 整体均方误差 =  0.18167194259555133\n",
      " train均方误差 =  0.24134516481911075\n",
      " test均方误差 =  0.24720678302731125\n",
      " 整体均方误差 =  0.2431048680692873\n",
      "Lasso\n",
      "----------begin----------------\n",
      " train均方误差 =  0.9876453112085596\n",
      " test均方误差 =  0.9226027495930467\n",
      " 整体均方误差 =  0.9681190297263401\n",
      " train均方误差 =  0.9879110945856205\n",
      " test均方误差 =  0.9210978700105859\n",
      " 整体均方误差 =  0.9678532463492788\n",
      "LassoCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10380088305526106\n",
      " test均方误差 =  0.12198050009761263\n",
      " 整体均方误差 =  0.10925854509671495\n",
      " train均方误差 =  0.10439488361907841\n",
      " test均方误差 =  0.1169916289821485\n",
      " 整体均方误差 =  0.10817652428036018\n",
      "LassoLars\n",
      "----------begin----------------\n",
      " train均方误差 =  0.9876453112085596\n",
      " test均方误差 =  0.9226027495930467\n",
      " 整体均方误差 =  0.9681190297263401\n",
      " train均方误差 =  0.9879110945856205\n",
      " test均方误差 =  0.9210978700105859\n",
      " 整体均方误差 =  0.9678532463492788\n",
      "LassoLarsCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10388371834531424\n",
      " test均方误差 =  0.12206401308742744\n",
      " 整体均方误差 =  0.10934158383749294\n",
      " train均方误差 =  0.10457914445920027\n",
      " test均方误差 =  0.11760026272183818\n",
      " 整体均方误差 =  0.10848818515646723\n",
      "LassoLarsIC\n",
      "----------begin----------------\n",
      " train均方误差 =  0.11422130953014663\n",
      " test均方误差 =  0.13517921909695574\n",
      " 整体均方误差 =  0.12051303653652597\n",
      " train均方误差 =  0.10475625302573123\n",
      " test均方误差 =  0.11810797409276519\n",
      " 整体均方误差 =  0.10876454324911021\n",
      "LinearRegression\n",
      "----------begin----------------\n",
      " train均方误差 =  0.1034479827941799\n",
      " test均方误差 =  0.12072414403164983\n",
      " 整体均方误差 =  0.10863442039559484\n",
      " train均方误差 =  0.10431402213051792\n",
      " test均方误差 =  0.11574172621241652\n",
      " 整体均方误差 =  0.10774470753183582\n",
      "Log\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "LogisticRegression\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "LogisticRegressionCV\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "ModifiedHuber\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "MultiTaskElasticNet\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "MultiTaskElasticNetCV\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "MultiTaskLasso\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "MultiTaskLassoCV\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "OrthogonalMatchingPursuit\n",
      "----------begin----------------\n",
      " train均方误差 =  0.15949143327042392\n",
      " test均方误差 =  0.1742488341479426\n",
      " 整体均方误差 =  0.16392171947569012\n",
      " train均方误差 =  0.14835649835966375\n",
      " test均方误差 =  0.1619856383729972\n",
      " 整体均方误差 =  0.1524480719024477\n",
      "OrthogonalMatchingPursuitCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.1391746264817531\n",
      " test均方误差 =  0.15915654066915513\n",
      " 整体均方误差 =  0.14517335210518714\n",
      " train均方误差 =  0.13748302675170718\n",
      " test均方误差 =  0.15447872354934405\n",
      " 整体均方误差 =  0.1425852667529368\n",
      "PassiveAggressiveClassifier\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "PassiveAggressiveRegressor\n",
      "----------begin----------------\n",
      " train均方误差 =  0.1739038861680391\n",
      " test均方误差 =  0.18705236831005356\n",
      " 整体均方误差 =  0.1778511624897588\n",
      " train均方误差 =  0.16295830530926098\n",
      " test均方误差 =  0.17354533004936915\n",
      " 整体均方误差 =  0.1661366122516688\n",
      "Perceptron\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "Ridge\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10348849392541223\n",
      " test均方误差 =  0.12102851251697887\n",
      " 整体均方误差 =  0.10875414355106607\n",
      " train均方误差 =  0.10427379529171317\n",
      " test均方误差 =  0.11591183843566032\n",
      " 整体均方误差 =  0.10776762611089676\n",
      "RidgeCV\n",
      "----------begin----------------\n",
      " train均方误差 =  0.1034484412700078\n",
      " test均方误差 =  0.12075222513398602\n",
      " 整体均方误差 =  0.10864317139814808\n",
      " train均方误差 =  0.10430771576226783\n",
      " test均方误差 =  0.11575725887296406\n",
      " 整体均方误差 =  0.10774495740941938\n",
      "RidgeClassifier\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "RidgeClassifierCV\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "SGDClassifier\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "SGDRegressor\n",
      "----------begin----------------\n",
      " train均方误差 =  0.11219964788534134\n",
      " test均方误差 =  0.13292156339016228\n",
      " 整体均方误差 =  0.11842052764388697\n",
      " train均方误差 =  0.11209420076167659\n",
      " test均方误差 =  0.12643321897607343\n",
      " 整体均方误差 =  0.1163988852464003\n",
      "SquaredLoss\n",
      "----------begin----------------\n",
      "----------failed----------------\n",
      "TheilSenRegressor\n",
      "----------begin----------------\n",
      " train均方误差 =  0.10880281590870292\n",
      " test均方误差 =  0.12297449168417854\n",
      " 整体均方误差 =  0.11305726289531556\n",
      " train均方误差 =  0.11028995556443204\n",
      " test均方误差 =  0.11852420422732154\n",
      " 整体均方误差 =  0.11276194087978007\n"
     ]
    }
   ],
   "source": [
    "df_train=pd.DataFrame.copy(data_train)\n",
    "df_train.drop( [\"V5\",'V22'],axis=1,inplace=True)\n",
    "\n",
    "y = df_train.target\n",
    "X = df_train.drop([\"target\"],axis=1)\n",
    "train_x, test_x, train_y, test_y=train_test_split(X,y,test_size=0.3,random_state=100)\n",
    "\n",
    "df_test=pd.DataFrame.copy(data_test)\n",
    "df_test.drop([\"V5\",\"V22\"],axis=1,inplace=True)\n",
    "\n",
    "i=0\n",
    "for model in models:\n",
    "    model_name=models_str[i]\n",
    "    i+=1\n",
    "    print(model_name)\n",
    "    print('----------begin----------------')\n",
    "\n",
    "    try:\n",
    "        # regressor=AdaBoostRegressor(base_estimator=model)#ElasticNet())\n",
    "        regressor=model\n",
    "        #LinearRegression())\n",
    "        regressor.fit(train_x,train_y)\n",
    "        pred_y = regressor.predict(train_x)\n",
    "        mse = mean_squared_error(train_y, pred_y)\n",
    "        print(\" train均方误差 = \",mse)\n",
    "\n",
    "        pred_y = regressor.predict(test_x)\n",
    "        mse = mean_squared_error(test_y, pred_y)\n",
    "        print(\" test均方误差 = \",mse)\n",
    "\n",
    "        pred_y = regressor.predict(X)\n",
    "        mse = mean_squared_error(y, pred_y)\n",
    "        print(\" 整体均方误差 = \",mse)\n",
    "\n",
    "        # 整体训练\n",
    "        regressor.fit(X,y)\n",
    "        pred_y = regressor.predict(train_x)\n",
    "        mse = mean_squared_error(train_y, pred_y)\n",
    "        print(\" train均方误差 = \",mse)\n",
    "\n",
    "        pred_y = regressor.predict(test_x)\n",
    "        mse = mean_squared_error(test_y, pred_y)\n",
    "        print(\" test均方误差 = \",mse)\n",
    "\n",
    "        pred_y = regressor.predict(X)\n",
    "        mse = mean_squared_error(y, pred_y)\n",
    "        print(\" 整体均方误差 = \",mse)\n",
    "\n",
    "        # 保cun\n",
    "\n",
    "\n",
    "        pred_y = regressor.predict(df_test)\n",
    "        pd_pred=pd.Series(pred_y)\n",
    "        pd_pred.to_csv('drop/'+model_name+'pred_ada_whole.txt',header=None,index=False)\n",
    "\n",
    "    except:\n",
    "        print('----------failed----------------')\n",
    "        pass"
   ]
  },
  {
   "source": [
    "## train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.DataFrame.copy(data_train)\n",
    "df_train.drop( [\"V5\",'V22'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train.target\n",
    "X = df_train.drop([\"target\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all=y.copy()\n",
    "X_all=X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = regressor.predict(X_all)\n",
    "        mse = mean_squared_error(y_all, pred_y)\n",
    "        print(\" 整体均方误差 = \",mse)"
   ]
  },
  {
   "source": [
    "def get_trainning_data_omitoutliers():\n",
    "    y_t=y.copy()\n",
    "    X_t=X.copy()\n",
    "    return X_t,y_t\n",
    "def rmse(y_true, y_pred):\n",
    "    diff = y_pred - y_true\n",
    "    sum_sq = sum(diff**2)    \n",
    "    n = len(y_pred)   \n",
    "    \n",
    "    return np.sqrt(sum_sq/n)\n",
    "def mse(y_ture,y_pred):\n",
    "    return mean_squared_error(y_ture,y_pred)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 108,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold, cross_val_score,cross_val_predict,KFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def train_model(model, param_grid=[], X=[], y=[], \n",
    "                splits=5, repeats=5):\n",
    "\n",
    "    # 获取数据\n",
    "    if len(y)==0:\n",
    "        X,y = get_trainning_data_omitoutliers()\n",
    "        \n",
    "    # 交叉验证\n",
    "    rkfold = RepeatedKFold(n_splits=splits, n_repeats=repeats)\n",
    "    \n",
    "    # 网格搜索最佳参数\n",
    "    if len(param_grid)>0:\n",
    "        gsearch = GridSearchCV(model, param_grid, cv=rkfold,\n",
    "                               scoring=\"neg_mean_squared_error\",\n",
    "                               verbose=1, return_train_score=True)\n",
    "\n",
    "        # 训练\n",
    "        gsearch.fit(X,y)\n",
    "\n",
    "        # 最好的模型\n",
    "        model = gsearch.best_estimator_        \n",
    "        best_idx = gsearch.best_index_\n",
    "\n",
    "        # 获取交叉验证评价指标\n",
    "        grid_results = pd.DataFrame(gsearch.cv_results_)\n",
    "        cv_mean = abs(grid_results.loc[best_idx,'mean_test_score'])\n",
    "        cv_std = grid_results.loc[best_idx,'std_test_score']\n",
    "\n",
    "    # 没有网格搜索  \n",
    "    else:\n",
    "        grid_results = []\n",
    "        cv_results = cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=rkfold)\n",
    "        cv_mean = abs(np.mean(cv_results))\n",
    "        cv_std = np.std(cv_results)\n",
    "    \n",
    "    # 合并数据\n",
    "    cv_score = pd.Series({'mean':cv_mean,'std':cv_std})\n",
    "\n",
    "   \n",
    "\n",
    "    pred_y = model.predict(X_all)\n",
    "    mse = mean_squared_error(y_all, pred_y)\n",
    "    print(\" 整体均方误差 = \",mse)\n",
    "    # 预测\n",
    "    y_pred = model.predict(X)\n",
    "    # 模型性能的统计数据        \n",
    "    print('----------------------')\n",
    "    print(model)\n",
    "    print('----------------------')\n",
    "    print('score=',model.score(X,y))\n",
    "    print('rmse=',rmse(y, y_pred))\n",
    "    print('mse=',mse(y, y_pred))\n",
    "    print('cross_val: mean=',cv_mean,', std=',cv_std)\n",
    "    \n",
    "    # 残差分析与可视化\n",
    "    y_pred = pd.Series(y_pred,index=y.index)\n",
    "    resid = y - y_pred\n",
    "    mean_resid = resid.mean()\n",
    "    std_resid = resid.std()\n",
    "    z = (resid - mean_resid)/std_resid    \n",
    "    n_outliers = sum(abs(z)>3)\n",
    "    outliers = z[abs(z)>3].index\n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    ax_131 = plt.subplot(1,3,1)\n",
    "    plt.plot(y,y_pred,'.')\n",
    "    plt.plot(y.loc[outliers],y_pred.loc[outliers],'ro')\n",
    "    plt.xlabel('y')\n",
    "    plt.ylabel('y_pred');\n",
    "    plt.title('corr = {:.3f}'.format(np.corrcoef(y,y_pred)[0][1]))\n",
    "    ax_132=plt.subplot(1,3,2)\n",
    "    plt.plot(y,y-y_pred,'.')\n",
    "    plt.plot(y.loc[outliers],y_pred.loc[outliers],'ro')\n",
    "    plt.xlabel('y')\n",
    "    plt.ylabel('y - y_pred');\n",
    "    plt.title('std resid = {:.3f}'.format(std_resid))\n",
    "    \n",
    "    ax_133=plt.subplot(1,3,3)\n",
    "    z.plot.hist(bins=50,ax=ax_133)\n",
    "    z.loc[outliers].plot.hist(color='r',bins=50,ax=ax_133)\n",
    "    plt.xlabel('z')\n",
    "    plt.title('{:.0f} samples with z>3'.format(n_outliers))\n",
    "\n",
    "    return model, cv_score, grid_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 整体均方误差 =  0.11759690096934088\n",
      " 整体均方误差 =  0.11759690096934088\n",
      "----------------------\n",
      "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n",
      "----------------------\n",
      "score= 0.8784971777354533\n",
      "rmse= 0.3429240454814169\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-a5c26de966e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" 整体均方误差 = \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, param_grid=[], X=[], y=[],  splits=5, repeats=5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-116-bd955016df67>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, param_grid, X, y, splits, repeats)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'score='\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rmse='\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mse='\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cross_val: mean='\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv_mean\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m', std='\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "model=SGDRegressor()\n",
    "reg=model.fit(X,y)\n",
    "pred_y = reg.predict(X_all)\n",
    "mse = mean_squared_error(y_all, pred_y)\n",
    "print(\" 整体均方误差 = \",mse)\n",
    "train_model(model)#, param_grid=[], X=[], y=[],  splits=5, repeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 房价预测结果  [18.825      10.78536585 13.39054054 17.4        23.57622951 22.0836478\n 27.68222222 17.9238806  27.68974359 20.17142857 28.06990291 33.1825\n 11.39387755 24.35358852 12.585      24.93566434 17.37971014 16.67857143\n 27.68974359 24.35358852 17.9238806  19.38632075 18.0920398  19.38632075\n 32.225      18.0920398  22.0836478  24.93566434 11.39387755 28.06990291\n 17.37971014 24.35358852 10.78536585 21.26363636 27.07674419 28.06990291\n 24.93566434 11.39387755 13.16       25.74481132 14.24666667 12.65443038\n 28.06990291 17.37971014 27.07674419 18.94666667 17.25       18.94666667\n 24.93566434 20.68333333 17.4        33.1825     16.64822335 17.37971014\n 25.74481132 20.56904762 24.93566434 16.67857143 24.35358852 22.0836478\n 18.0920398  16.21538462 42.52222222 20.56904762 17.37971014 26.80766284\n 24.93566434 11.39387755 17.9238806  27.07674419 22.40368664 17.74545455\n 17.9238806  26.80766284 19.38632075 42.44117647 16.13291139 11.39387755\n 16.23333333 24.35358852 20.32931034 13.39054054 12.26       24.35358852\n 20.56904762 21.26363636 48.12068966 16.84444444 44.23333333 35.975\n 27.88223684 19.38632075 18.88152174 17.64375    15.58461538 33.978\n 23.57622951 22.0836478  18.52894737 17.9238806  14.24666667 19.38632075\n 27.68222222 24.93566434 11.39387755 16.64822335 11.14285714 27.07674419\n 12.585      24.93566434 50.         12.585      16.84444444 24.93566434\n 28.06990291 23.57622951 22.0836478  20.68333333 27.07674419 20.68333333\n 19.58245614 17.9238806  12.585      20.68333333 21.84875    16.23333333\n 42.22307692]\n 均方误差 =  16.95\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 加载数据\n",
    "data=load_boston()\n",
    "# 分割数据\n",
    "train_x, test_x, train_y, test_y = train_test_split(data.data, data.target, test_size=0.25, random_state=33)\n",
    "# 使用 AdaBoost 回归模型\n",
    "regressor=AdaBoostRegressor()\n",
    "regressor.fit(train_x,train_y)\n",
    "pred_y = regressor.predict(test_x)\n",
    "mse = mean_squared_error(test_y, pred_y)\n",
    "print(\" 房价预测结果 \", pred_y)\n",
    "print(\" 均方误差 = \",round(mse,2))"
   ]
  }
 ]
}